# n8n-Agent: Workflow Automation Platform Implementation Plan

**Created**: Nov 21, 2025
**Branch**: `n8n-agent`
**Worktree**: `/Users/chocho/projects/e2b-hack-n8n-agent`

---

## Project Goal

Transform the existing E2B + Claude Agent SDK demo into a **general-purpose workflow automation platform** where:
1. User describes an automation problem in natural language
2. Master agent analyzes and creates an execution plan
3. User reviews and approves the plan
4. Slave sandboxes execute tasks using Docker MCP servers
5. Results are aggregated and presented

---

## Key Decisions

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Timeline | 12+ hours | Full platform implementation |
| Human-in-the-loop | Yes, show plan first | User approves before execution |
| MCP Strategy | Docker MCPs (native E2B) | Available out of the box in E2B |
| Demo Focus | General purpose | Any user-described automation |

---

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│  USER INTERFACE                                                          │
│  ┌─────────────────────────────────────────────────────────────────────┐│
│  │ 1. Problem Input → 2. Plan Review → 3. Approve → 4. Monitor → 5. Results ││
│  └─────────────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  MASTER SANDBOX (Orchestrator)                                           │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐                   │
│  │ MCP Registry │  │ Planner Agent│  │Workflow Engine│                   │
│  │ (discovery)  │  │ (decompose)  │  │ (execute)    │                   │
│  └──────────────┘  └──────────────┘  └──────────────┘                   │
└─────────────────────────────────────────────────────────────────────────┘
                         │ spawns
          ┌──────────────┼──────────────┐
          ▼              ▼              ▼
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│ Slave + MCP │  │ Slave + MCP │  │ Slave + MCP │
│ (research)  │  │ (code)      │  │ (data)      │
└─────────────┘  └─────────────┘  └─────────────┘
```

---

## File Structure (Final)

```
e2b_platform/
├── main.py              # Entry point (modified)
├── config.py            # Configuration (modified)
├── ui_server.py         # Flask UI (major rewrite)
├── models.py            # NEW: Data models
├── mcp_registry.py      # NEW: MCP server catalog
├── planner.py           # NEW: Planner agent
├── workflow_engine.py   # NEW: Orchestration
├── slave_agent.py       # NEW: Enhanced agent (replaces agent_task.py)
├── requirements.txt     # Dependencies
└── test_file.txt        # Demo content
```

---

## Implementation Phases

### Phase 1: Core Data Models (`models.py`)

**Purpose**: Foundation dataclasses for the entire system

```python
from dataclasses import dataclass, field
from typing import Optional
from enum import Enum
import uuid

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class MCPCategory(Enum):
    DATABASE = "database"
    API = "api"
    FILE_SYSTEM = "filesystem"
    CLOUD = "cloud"
    COMMUNICATION = "communication"
    DEVELOPMENT = "development"
    AI_ML = "ai_ml"
    SEARCH = "search"
    PRODUCTIVITY = "productivity"
    OTHER = "other"

@dataclass
class MCPServerConfig:
    """Configuration for an MCP server."""
    name: str
    image: str  # Docker image name, e.g., "mcp/github"
    env_vars: dict = field(default_factory=dict)

@dataclass
class Task:
    """A single task in a workflow."""
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    name: str = ""
    description: str = ""
    prompt: str = ""  # The actual prompt for the agent
    mcp_servers: list[MCPServerConfig] = field(default_factory=list)
    depends_on: list[str] = field(default_factory=list)  # Task IDs
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[str] = None
    error: Optional[str] = None
    sandbox_id: Optional[str] = None

@dataclass
class WorkflowPlan:
    """Complete execution plan generated by planner."""
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    problem_description: str = ""
    tasks: list[Task] = field(default_factory=list)
    summary: str = ""  # Human-readable summary
    estimated_complexity: str = "medium"  # low, medium, high

    def get_execution_order(self) -> list[list[Task]]:
        """Return tasks grouped by execution level (parallel batches)."""
        # Topological sort respecting dependencies
        pass

    def to_dict(self) -> dict:
        """Serialize for JSON transport."""
        pass

    @classmethod
    def from_dict(cls, data: dict) -> 'WorkflowPlan':
        """Deserialize from JSON."""
        pass

@dataclass
class ExecutionStatus:
    """Current state of workflow execution."""
    workflow_id: str
    status: str  # planning, awaiting_approval, executing, completed, failed
    current_task: Optional[str] = None
    completed_tasks: list[str] = field(default_factory=list)
    failed_tasks: list[str] = field(default_factory=list)
    results: dict = field(default_factory=dict)
```

---

### Phase 2: MCP Registry (`mcp_registry.py`)

**Purpose**: Catalog of Docker MCP servers with discovery and suggestion

```python
"""
MCP Registry - Discovers and manages MCP servers from Docker Hub

Features:
1. Pre-defined catalog of 15+ MCP servers
2. Category-based organization
3. Task-based suggestion engine
4. Docker config generation for Claude Agent SDK
"""

from dataclasses import dataclass, field
from typing import Optional
from models import MCPCategory

@dataclass
class MCPServer:
    """Represents an MCP server from Docker Hub."""
    name: str
    image: str  # e.g., "mcp/postgres"
    description: str
    category: MCPCategory
    env_vars: list[str] = field(default_factory=list)  # Required env vars
    capabilities: list[str] = field(default_factory=list)
    tools: list[str] = field(default_factory=list)

# Pre-defined registry
MCP_SERVERS = {
    # === DATABASE ===
    "postgres": MCPServer(
        name="PostgreSQL",
        image="mcp/postgres",
        description="Read-only SQL access to PostgreSQL databases",
        category=MCPCategory.DATABASE,
        env_vars=["POSTGRES_CONNECTION_STRING"],
        capabilities=["query", "schema_inspection"],
        tools=["query", "list_tables", "describe_table"]
    ),
    "sqlite": MCPServer(
        name="SQLite",
        image="mcp/sqlite",
        description="Local SQLite database operations",
        category=MCPCategory.DATABASE,
        env_vars=["SQLITE_DB_PATH"],
        capabilities=["query", "schema_inspection", "write"],
        tools=["query", "list_tables", "create_table"]
    ),

    # === API / HTTP ===
    "fetch": MCPServer(
        name="Fetch",
        image="mcp/fetch",
        description="HTTP requests and web content fetching",
        category=MCPCategory.API,
        env_vars=[],
        capabilities=["http_get", "http_post", "html_parse"],
        tools=["fetch", "fetch_html", "fetch_json"]
    ),

    # === DEVELOPMENT ===
    "github": MCPServer(
        name="GitHub",
        image="mcp/github",
        description="GitHub API operations - repos, issues, PRs",
        category=MCPCategory.DEVELOPMENT,
        env_vars=["GITHUB_TOKEN"],
        capabilities=["repos", "issues", "pull_requests", "files"],
        tools=["list_repos", "create_issue", "get_file_contents", "create_pr"]
    ),
    "git": MCPServer(
        name="Git",
        image="mcp/git",
        description="Git repository operations",
        category=MCPCategory.DEVELOPMENT,
        env_vars=["GIT_REPO_PATH"],
        capabilities=["clone", "commit", "branch", "diff"],
        tools=["git_status", "git_diff", "git_commit", "git_log"]
    ),
    "sentry": MCPServer(
        name="Sentry",
        image="mcp/sentry",
        description="Sentry error tracking integration",
        category=MCPCategory.DEVELOPMENT,
        env_vars=["SENTRY_AUTH_TOKEN", "SENTRY_ORG"],
        capabilities=["issues", "events", "projects"],
        tools=["list_issues", "get_issue", "resolve_issue"]
    ),

    # === COMMUNICATION ===
    "slack": MCPServer(
        name="Slack",
        image="mcp/slack",
        description="Slack messaging and channel management",
        category=MCPCategory.COMMUNICATION,
        env_vars=["SLACK_BOT_TOKEN", "SLACK_TEAM_ID"],
        capabilities=["messaging", "channels", "users"],
        tools=["send_message", "list_channels", "get_channel_history"]
    ),

    # === SEARCH ===
    "brave-search": MCPServer(
        name="Brave Search",
        image="mcp/brave-search",
        description="Web and local search using Brave API",
        category=MCPCategory.SEARCH,
        env_vars=["BRAVE_API_KEY"],
        capabilities=["web_search", "local_search"],
        tools=["search_web", "search_local"]
    ),
    "exa": MCPServer(
        name="Exa",
        image="mcp/exa",
        description="AI-powered semantic search",
        category=MCPCategory.SEARCH,
        env_vars=["EXA_API_KEY"],
        capabilities=["semantic_search", "similarity"],
        tools=["search", "find_similar", "get_contents"]
    ),

    # === FILE SYSTEM ===
    "filesystem": MCPServer(
        name="Filesystem",
        image="mcp/filesystem",
        description="Local filesystem operations with sandboxing",
        category=MCPCategory.FILE_SYSTEM,
        env_vars=["ALLOWED_DIRECTORIES"],
        capabilities=["read", "write", "list", "search"],
        tools=["read_file", "write_file", "list_directory", "search_files"]
    ),

    # === CLOUD ===
    "aws-kb": MCPServer(
        name="AWS Knowledge Base",
        image="mcp/aws-kb-retrieval-server",
        description="AWS Bedrock Knowledge Base retrieval",
        category=MCPCategory.CLOUD,
        env_vars=["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY", "AWS_REGION"],
        capabilities=["knowledge_retrieval", "rag"],
        tools=["retrieve", "query_knowledge_base"]
    ),

    # === PRODUCTIVITY ===
    "google-drive": MCPServer(
        name="Google Drive",
        image="mcp/gdrive",
        description="Google Drive file access and search",
        category=MCPCategory.PRODUCTIVITY,
        env_vars=["GOOGLE_CREDENTIALS"],
        capabilities=["search", "read", "export"],
        tools=["search_files", "read_file", "export_document"]
    ),
    "google-maps": MCPServer(
        name="Google Maps",
        image="mcp/google-maps",
        description="Google Maps for location and directions",
        category=MCPCategory.PRODUCTIVITY,
        env_vars=["GOOGLE_MAPS_API_KEY"],
        capabilities=["geocoding", "directions", "places"],
        tools=["geocode", "get_directions", "search_places"]
    ),

    # === AI/ML ===
    "memory": MCPServer(
        name="Memory",
        image="mcp/memory",
        description="Persistent memory using knowledge graph",
        category=MCPCategory.AI_ML,
        env_vars=[],
        capabilities=["store", "retrieve", "relate"],
        tools=["create_entities", "create_relations", "search_nodes"]
    ),

    # === BROWSER AUTOMATION ===
    "puppeteer": MCPServer(
        name="Puppeteer",
        image="mcp/puppeteer",
        description="Browser automation and web scraping",
        category=MCPCategory.DEVELOPMENT,
        env_vars=[],
        capabilities=["navigate", "screenshot", "interact", "scrape"],
        tools=["navigate", "screenshot", "click", "type", "evaluate"]
    ),

    # === UTILITY ===
    "time": MCPServer(
        name="Time",
        image="mcp/time",
        description="Time and timezone operations",
        category=MCPCategory.OTHER,
        env_vars=[],
        capabilities=["current_time", "timezone_conversion"],
        tools=["get_current_time", "convert_timezone"]
    ),
}


class MCPRegistry:
    """Registry for discovering and managing MCP servers."""

    def __init__(self):
        self.servers = MCP_SERVERS.copy()

    def list_all(self) -> list[MCPServer]:
        """List all registered MCP servers."""
        return list(self.servers.values())

    def list_by_category(self, category: MCPCategory) -> list[MCPServer]:
        """List servers by category."""
        return [s for s in self.servers.values() if s.category == category]

    def get_server(self, name: str) -> Optional[MCPServer]:
        """Get a specific server by name."""
        return self.servers.get(name)

    def search(self, query: str) -> list[MCPServer]:
        """Search servers by name, description, or capabilities."""
        query = query.lower()
        results = []
        for server in self.servers.values():
            if (query in server.name.lower() or
                query in server.description.lower() or
                any(query in cap.lower() for cap in server.capabilities) or
                any(query in tool.lower() for tool in server.tools)):
                results.append(server)
        return results

    def suggest_for_task(self, task_description: str) -> list[MCPServer]:
        """Suggest MCP servers based on task description."""
        task_lower = task_description.lower()
        suggestions = []

        # Keyword-based matching
        keyword_map = {
            "database": ["postgres", "sqlite"],
            "sql": ["postgres", "sqlite"],
            "api": ["fetch"],
            "http": ["fetch"],
            "web": ["fetch", "puppeteer", "brave-search"],
            "scrape": ["puppeteer", "fetch"],
            "github": ["github", "git"],
            "git": ["git", "github"],
            "slack": ["slack"],
            "message": ["slack"],
            "file": ["filesystem", "google-drive"],
            "search": ["brave-search", "exa"],
            "google": ["google-drive", "google-maps"],
            "map": ["google-maps"],
            "location": ["google-maps"],
            "error": ["sentry"],
            "bug": ["sentry", "github"],
            "time": ["time"],
            "schedule": ["time"],
            "memory": ["memory"],
            "remember": ["memory"],
            "browser": ["puppeteer"],
            "automate": ["puppeteer", "github", "slack"],
            "news": ["brave-search", "fetch"],
            "research": ["brave-search", "exa"],
        }

        seen = set()
        for keyword, server_names in keyword_map.items():
            if keyword in task_lower:
                for name in server_names:
                    if name not in seen and name in self.servers:
                        suggestions.append(self.servers[name])
                        seen.add(name)

        return suggestions

    def get_docker_config(self, server_name: str, env_values: dict = None) -> dict:
        """Generate Docker MCP config for Claude Agent SDK mcp_servers parameter."""
        server = self.get_server(server_name)
        if not server:
            raise ValueError(f"Unknown MCP server: {server_name}")

        env_values = env_values or {}

        config = {
            "name": server_name,
            "type": "docker",
            "image": server.image,
            "env": {}
        }

        for env_var in server.env_vars:
            if env_var in env_values:
                config["env"][env_var] = env_values[env_var]

        return config

    def get_catalog_for_planner(self) -> str:
        """Generate a text catalog for the planner agent's context."""
        lines = ["# Available MCP Servers\n"]

        for category in MCPCategory:
            servers = self.list_by_category(category)
            if servers:
                lines.append(f"\n## {category.value.replace('_', ' ').title()}\n")
                for server in servers:
                    lines.append(f"**{server.name}** (`{server.image}`)")
                    lines.append(f"  {server.description}")
                    if server.tools:
                        lines.append(f"  Tools: {', '.join(server.tools)}")
                    if server.env_vars:
                        lines.append(f"  Requires: {', '.join(server.env_vars)}")
                    lines.append("")

        return "\n".join(lines)


# Global instance
registry = MCPRegistry()
```

---

### Phase 3: Planner Agent (`planner.py`)

**Purpose**: Use Claude to decompose problems into executable task graphs

```python
"""
Planner Agent - Decomposes user problems into workflow plans

Uses Claude to:
1. Analyze the problem
2. Identify required capabilities
3. Select appropriate MCP servers
4. Create task graph with dependencies
"""

import json
import os
from claude_agent_sdk import query, ClaudeAgentOptions
from models import WorkflowPlan, Task, MCPServerConfig
from mcp_registry import registry

PLANNER_SYSTEM_PROMPT = '''You are a workflow planning agent. Your job is to decompose user problems into executable task graphs.

You have access to these MCP servers that can be used by worker agents:

{mcp_catalog}

When creating a plan:
1. Break the problem into discrete, independent tasks where possible
2. Identify dependencies between tasks (what needs to complete before what)
3. Select the most appropriate MCP servers for each task
4. Keep tasks focused - one clear objective per task

Output your plan as JSON with this exact structure:
{{
    "summary": "Brief description of the overall approach",
    "estimated_complexity": "low|medium|high",
    "tasks": [
        {{
            "id": "task_1",
            "name": "Short task name",
            "description": "What this task accomplishes",
            "prompt": "The actual prompt to give the worker agent",
            "mcp_servers": ["server_name_1", "server_name_2"],
            "depends_on": []  // List of task IDs that must complete first
        }}
    ]
}}

IMPORTANT:
- Only use MCP servers from the catalog above
- Tasks with no dependencies can run in parallel
- Keep prompts specific and actionable
- Include all necessary context in each task's prompt
'''


class PlannerAgent:
    """Generates workflow plans from problem descriptions."""

    def __init__(self, model: str = "claude-sonnet-4-20250514"):
        self.model = model
        self.mcp_catalog = registry.get_catalog_for_planner()

    async def create_plan(self, problem_description: str) -> WorkflowPlan:
        """Generate a workflow plan for the given problem."""

        system_prompt = PLANNER_SYSTEM_PROMPT.format(mcp_catalog=self.mcp_catalog)

        options = ClaudeAgentOptions(
            model=self.model,
            system_prompt=system_prompt,
            max_turns=1,
        )

        prompt = f"""Create an execution plan for this automation problem:

{problem_description}

Output only valid JSON matching the required schema."""

        result_text = ""
        async for message in query(prompt=prompt, options=options):
            # Extract text from message
            msg_type = type(message).__name__
            if msg_type == 'AssistantMessage':
                if hasattr(message, 'content') and message.content:
                    for block in message.content:
                        if hasattr(block, 'text'):
                            result_text += block.text
            elif msg_type == 'ResultMessage':
                if hasattr(message, 'result') and message.result:
                    result_text = message.result

        # Parse the JSON response
        plan_data = self._parse_plan_json(result_text)

        # Convert to WorkflowPlan
        return self._build_workflow_plan(problem_description, plan_data)

    def _parse_plan_json(self, text: str) -> dict:
        """Extract and parse JSON from planner response."""
        # Find JSON in response (may have markdown code blocks)
        text = text.strip()
        if text.startswith("```"):
            # Remove markdown code block
            lines = text.split("\n")
            text = "\n".join(lines[1:-1])

        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            raise ValueError(f"Failed to parse planner response as JSON: {e}")

    def _build_workflow_plan(self, problem: str, data: dict) -> WorkflowPlan:
        """Build WorkflowPlan from parsed JSON."""
        tasks = []
        for task_data in data.get("tasks", []):
            mcp_configs = []
            for server_name in task_data.get("mcp_servers", []):
                server = registry.get_server(server_name)
                if server:
                    mcp_configs.append(MCPServerConfig(
                        name=server_name,
                        image=server.image,
                        env_vars={}  # Will be filled in at execution time
                    ))

            tasks.append(Task(
                id=task_data.get("id", ""),
                name=task_data.get("name", ""),
                description=task_data.get("description", ""),
                prompt=task_data.get("prompt", ""),
                mcp_servers=mcp_configs,
                depends_on=task_data.get("depends_on", []),
            ))

        return WorkflowPlan(
            problem_description=problem,
            tasks=tasks,
            summary=data.get("summary", ""),
            estimated_complexity=data.get("estimated_complexity", "medium"),
        )

    def validate_plan(self, plan: WorkflowPlan) -> tuple[bool, list[str]]:
        """Validate a workflow plan for executability."""
        errors = []

        # Check for empty plan
        if not plan.tasks:
            errors.append("Plan has no tasks")

        # Check task IDs are unique
        task_ids = [t.id for t in plan.tasks]
        if len(task_ids) != len(set(task_ids)):
            errors.append("Duplicate task IDs found")

        # Check dependencies reference valid tasks
        for task in plan.tasks:
            for dep_id in task.depends_on:
                if dep_id not in task_ids:
                    errors.append(f"Task {task.id} depends on unknown task {dep_id}")

        # Check for circular dependencies
        if self._has_circular_deps(plan.tasks):
            errors.append("Circular dependencies detected")

        # Check MCP servers exist
        for task in plan.tasks:
            for mcp in task.mcp_servers:
                if not registry.get_server(mcp.name):
                    errors.append(f"Task {task.id} uses unknown MCP server: {mcp.name}")

        return len(errors) == 0, errors

    def _has_circular_deps(self, tasks: list[Task]) -> bool:
        """Check for circular dependencies using DFS."""
        task_map = {t.id: t for t in tasks}
        visited = set()
        rec_stack = set()

        def dfs(task_id):
            visited.add(task_id)
            rec_stack.add(task_id)

            task = task_map.get(task_id)
            if task:
                for dep_id in task.depends_on:
                    if dep_id not in visited:
                        if dfs(dep_id):
                            return True
                    elif dep_id in rec_stack:
                        return True

            rec_stack.remove(task_id)
            return False

        for task in tasks:
            if task.id not in visited:
                if dfs(task.id):
                    return True

        return False
```

---

### Phase 4: Slave Agent (`slave_agent.py`)

**Purpose**: Enhanced agent that runs in slave sandboxes with MCP support

```python
"""
Slave Agent - Executes individual tasks with MCP support

Runs inside E2B slave sandboxes and:
1. Loads task configuration from runtime_config.json
2. Initializes specified MCP servers
3. Executes task using Claude Agent SDK
4. Returns structured results
"""

import asyncio
import os
import json
from claude_agent_sdk import query, ClaudeAgentOptions


def load_task_config() -> dict:
    """Load task configuration from JSON file."""
    config_path = '/home/user/task_config.json'

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Task config not found at {config_path}")

    with open(config_path, 'r') as f:
        return json.load(f)


def build_mcp_servers(mcp_configs: list[dict]) -> list[dict]:
    """Build MCP server configurations for Claude Agent SDK."""
    servers = []
    for mcp in mcp_configs:
        server_config = {
            "name": mcp["name"],
            "type": "docker",
            "image": mcp["image"],
        }
        if mcp.get("env_vars"):
            server_config["env"] = mcp["env_vars"]
        servers.append(server_config)
    return servers


def extract_text_from_message(message) -> str:
    """Extract clean text content from SDK message objects."""
    msg_type = type(message).__name__

    if msg_type == 'AssistantMessage':
        if hasattr(message, 'content') and message.content:
            texts = []
            for block in message.content:
                if hasattr(block, 'text'):
                    texts.append(block.text)
            return '\n'.join(texts)

    elif msg_type == 'ResultMessage':
        if hasattr(message, 'result') and message.result:
            return message.result

    return ''


async def execute_task(config: dict) -> dict:
    """Execute the task and return results."""

    task_id = config.get('task_id', 'unknown')
    prompt = config.get('prompt', '')
    system_prompt = config.get('system_prompt', 'You are a helpful automation agent.')
    model = config.get('model', 'claude-sonnet-4-20250514')
    max_turns = config.get('max_turns', 10)
    mcp_configs = config.get('mcp_servers', [])

    # Build MCP server list
    mcp_servers = build_mcp_servers(mcp_configs) if mcp_configs else None

    # Set max tokens via environment
    max_tokens = config.get('max_tokens', 200000)
    os.environ['CLAUDE_CODE_MAX_OUTPUT_TOKENS'] = str(max_tokens)

    # Build SDK options
    options = ClaudeAgentOptions(
        model=model,
        system_prompt=system_prompt,
        max_turns=max_turns,
    )

    # Add MCP servers if specified
    if mcp_servers:
        options.mcp_servers = mcp_servers

    # Execute
    result_text = None
    try:
        async for message in query(prompt=prompt, options=options):
            text = extract_text_from_message(message)
            if text:
                result_text = text

        return {
            "task_id": task_id,
            "status": "completed",
            "result": result_text or "Task completed with no output.",
            "error": None
        }

    except Exception as e:
        return {
            "task_id": task_id,
            "status": "failed",
            "result": None,
            "error": str(e)
        }


async def main():
    """Main entry point for slave agent."""

    print("Loading task configuration...", flush=True)
    config = load_task_config()

    print(f"Executing task: {config.get('task_id', 'unknown')}", flush=True)
    print(f"MCP servers: {[m['name'] for m in config.get('mcp_servers', [])]}", flush=True)

    result = await execute_task(config)

    # Output result as JSON for easy parsing
    print("=" * 50, flush=True)
    print("TASK_RESULT_JSON", flush=True)
    print("=" * 50, flush=True)
    print(json.dumps(result, indent=2), flush=True)
    print("=" * 50, flush=True)

    # Also save to file
    with open('/home/user/task_result.json', 'w') as f:
        json.dump(result, f, indent=2)


if __name__ == "__main__":
    asyncio.run(main())
```

---

### Phase 5: Workflow Engine (`workflow_engine.py`)

**Purpose**: Orchestrates multi-agent execution

```python
"""
Workflow Engine - Orchestrates multi-agent workflow execution

Responsibilities:
1. Parse WorkflowPlan into execution DAG
2. Spawn slave sandboxes with correct configs
3. Execute tasks respecting dependencies
4. Handle failures and retries
5. Aggregate results
"""

import asyncio
import json
import os
from typing import AsyncGenerator
from dataclasses import dataclass
from e2b_code_interpreter import Sandbox

from models import WorkflowPlan, Task, TaskStatus, ExecutionStatus
import config


@dataclass
class StatusUpdate:
    """Status update for SSE streaming."""
    type: str  # task_started, task_progress, task_completed, task_failed, workflow_done
    task_id: str = None
    message: str = ""
    data: dict = None


class WorkflowEngine:
    """Executes workflow plans using E2B slave sandboxes."""

    def __init__(self, anthropic_api_key: str, e2b_api_key: str):
        self.anthropic_api_key = anthropic_api_key
        self.e2b_api_key = e2b_api_key
        self.active_sandboxes: dict[str, Sandbox] = {}

    async def execute(self, plan: WorkflowPlan) -> AsyncGenerator[StatusUpdate, None]:
        """Execute workflow plan, yielding status updates."""

        # Build execution order (topological sort)
        levels = self._get_execution_levels(plan)
        results = {}

        for level_idx, level_tasks in enumerate(levels):
            yield StatusUpdate(
                type="level_started",
                message=f"Starting execution level {level_idx + 1} with {len(level_tasks)} tasks"
            )

            # Execute tasks in this level in parallel
            level_results = await asyncio.gather(*[
                self._execute_task(task, results)
                for task in level_tasks
            ], return_exceptions=True)

            # Process results
            for task, result in zip(level_tasks, level_results):
                if isinstance(result, Exception):
                    task.status = TaskStatus.FAILED
                    task.error = str(result)
                    yield StatusUpdate(
                        type="task_failed",
                        task_id=task.id,
                        message=f"Task {task.name} failed: {result}",
                        data={"error": str(result)}
                    )
                else:
                    task.status = TaskStatus.COMPLETED
                    task.result = result.get("result")
                    results[task.id] = result
                    yield StatusUpdate(
                        type="task_completed",
                        task_id=task.id,
                        message=f"Task {task.name} completed",
                        data=result
                    )

        # Cleanup sandboxes
        await self._cleanup()

        yield StatusUpdate(
            type="workflow_done",
            message="Workflow execution completed",
            data={"results": results}
        )

    async def _execute_task(self, task: Task, previous_results: dict) -> dict:
        """Execute a single task in a slave sandbox."""

        task.status = TaskStatus.RUNNING

        # Create slave sandbox
        sandbox = Sandbox.create(
            template=config.SLAVE_TEMPLATE,
            timeout=config.SLAVE_TIMEOUT
        )
        task.sandbox_id = sandbox.get_info().sandbox_id
        self.active_sandboxes[task.id] = sandbox

        try:
            # Prepare task config
            task_config = {
                "task_id": task.id,
                "prompt": self._build_prompt(task, previous_results),
                "system_prompt": f"You are executing task: {task.name}. {task.description}",
                "model": config.AGENT_MODEL,
                "max_turns": 10,
                "max_tokens": config.AGENT_MAX_TOKENS,
                "mcp_servers": [
                    {"name": mcp.name, "image": mcp.image, "env_vars": mcp.env_vars}
                    for mcp in task.mcp_servers
                ]
            }

            # Upload task config
            sandbox.files.write(
                "/home/user/task_config.json",
                json.dumps(task_config, indent=2)
            )

            # Upload slave agent script
            # (In real implementation, this would be pre-installed in template)
            sandbox.files.write("/home/user/slave_agent.py", SLAVE_AGENT_CODE)

            # Execute
            result = sandbox.commands.run(
                f"ANTHROPIC_API_KEY={self.anthropic_api_key} python /home/user/slave_agent.py",
                timeout=config.AGENT_TASK_TIMEOUT
            )

            # Parse result
            result_json = sandbox.files.read("/home/user/task_result.json")
            return json.loads(result_json)

        finally:
            # Cleanup this sandbox
            try:
                sandbox.kill()
            except:
                pass
            del self.active_sandboxes[task.id]

    def _build_prompt(self, task: Task, previous_results: dict) -> str:
        """Build task prompt including context from previous tasks."""
        prompt = task.prompt

        if task.depends_on and previous_results:
            context = "\n\n## Context from previous tasks:\n"
            for dep_id in task.depends_on:
                if dep_id in previous_results:
                    dep_result = previous_results[dep_id]
                    context += f"\n### Result from {dep_id}:\n{dep_result.get('result', 'No result')}\n"
            prompt = context + "\n\n## Your task:\n" + prompt

        return prompt

    def _get_execution_levels(self, plan: WorkflowPlan) -> list[list[Task]]:
        """Get tasks grouped by execution level (parallel batches)."""
        task_map = {t.id: t for t in plan.tasks}
        levels = []
        completed = set()
        remaining = set(t.id for t in plan.tasks)

        while remaining:
            # Find tasks whose dependencies are all completed
            ready = []
            for task_id in remaining:
                task = task_map[task_id]
                if all(dep in completed for dep in task.depends_on):
                    ready.append(task)

            if not ready:
                # Circular dependency or error
                break

            levels.append(ready)
            for task in ready:
                completed.add(task.id)
                remaining.remove(task.id)

        return levels

    async def _cleanup(self):
        """Kill any remaining sandboxes."""
        for task_id, sandbox in list(self.active_sandboxes.items()):
            try:
                sandbox.kill()
            except:
                pass
        self.active_sandboxes.clear()

    def cancel(self):
        """Cancel execution and cleanup."""
        asyncio.create_task(self._cleanup())


# Slave agent code to upload (or pre-install in template)
SLAVE_AGENT_CODE = '''
# ... (content of slave_agent.py)
'''
```

---

### Phase 6: UI Server Updates (`ui_server.py`)

**Key changes to existing file:**

#### New HTML Sections:

```html
<!-- 1. Problem Input (replaces file upload as primary action) -->
<div class="problem-input-section">
    <h3>Describe Your Automation Problem</h3>
    <textarea id="problemDescription" rows="6"
        placeholder="e.g., 'Search for today's top tech news, analyze sentiment, and post a summary to Slack'"></textarea>
    <button onclick="generatePlan()" class="btn-primary">Generate Plan</button>
</div>

<!-- 2. Plan Review Section (shown after plan generated) -->
<div class="plan-review-section" id="planReview" style="display: none;">
    <h3>Execution Plan</h3>
    <div class="plan-summary" id="planSummary"></div>
    <div class="task-graph" id="taskGraph">
        <!-- Task cards with dependencies visualized -->
    </div>
    <div class="plan-actions">
        <button onclick="approvePlan()" class="btn-success">Approve & Execute</button>
        <button onclick="rejectPlan()" class="btn-secondary">Modify Problem</button>
    </div>
</div>

<!-- 3. Execution Monitor (shows during execution) -->
<div class="execution-monitor" id="executionMonitor" style="display: none;">
    <h3>Execution Progress</h3>
    <div class="agent-grid" id="agentGrid">
        <!-- Dynamically populated agent cards -->
    </div>
</div>

<!-- 4. Results Section -->
<div class="results-section" id="resultsSection" style="display: none;">
    <h3>Workflow Results</h3>
    <div class="aggregated-result" id="aggregatedResult"></div>
    <details>
        <summary>Individual Task Results</summary>
        <div id="taskResults"></div>
    </details>
</div>
```

#### New Flask Routes:

```python
@app.route('/api/plan', methods=['POST'])
def generate_plan():
    """Generate workflow plan from problem description."""
    problem = request.json.get('problem')

    planner = PlannerAgent()
    plan = await planner.create_plan(problem)

    valid, errors = planner.validate_plan(plan)

    return jsonify({
        'plan': plan.to_dict(),
        'valid': valid,
        'errors': errors
    })

@app.route('/api/execute', methods=['POST'])
def execute_plan():
    """Execute approved workflow plan."""
    plan_data = request.json.get('plan')
    plan = WorkflowPlan.from_dict(plan_data)

    # Store execution ID for SSE
    execution_id = str(uuid.uuid4())[:8]
    active_executions[execution_id] = plan

    return jsonify({'execution_id': execution_id})

@app.route('/api/stream/<execution_id>')
def stream_execution(execution_id):
    """SSE endpoint for execution updates."""
    def generate():
        plan = active_executions.get(execution_id)
        if not plan:
            yield f"data: {json.dumps({'error': 'Execution not found'})}\n\n"
            return

        engine = WorkflowEngine(
            anthropic_api_key=os.getenv('ANTHROPIC_API_KEY'),
            e2b_api_key=os.getenv('E2B_API_KEY')
        )

        async def run():
            async for update in engine.execute(plan):
                yield f"data: {json.dumps(update.__dict__)}\n\n"

        # Run async generator
        for update in asyncio.run(collect_updates(engine, plan)):
            yield f"data: {json.dumps(update)}\n\n"

    return Response(generate(), mimetype='text/event-stream')
```

#### New JavaScript:

```javascript
let currentPlan = null;

async function generatePlan() {
    const problem = document.getElementById('problemDescription').value;
    if (!problem.trim()) {
        alert('Please describe your automation problem');
        return;
    }

    showSection('loading');

    const response = await fetch('/api/plan', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({problem})
    });

    const data = await response.json();
    currentPlan = data.plan;

    renderPlanReview(data);
    showSection('planReview');
}

function renderPlanReview(data) {
    const {plan, valid, errors} = data;

    document.getElementById('planSummary').innerHTML = `
        <p><strong>Summary:</strong> ${plan.summary}</p>
        <p><strong>Complexity:</strong> ${plan.estimated_complexity}</p>
        <p><strong>Tasks:</strong> ${plan.tasks.length}</p>
    `;

    const taskGraph = document.getElementById('taskGraph');
    taskGraph.innerHTML = plan.tasks.map(task => `
        <div class="task-card" data-task-id="${task.id}">
            <div class="task-header">
                <span class="task-name">${task.name}</span>
                <span class="task-status pending">Pending</span>
            </div>
            <div class="task-description">${task.description}</div>
            <div class="task-mcps">
                ${task.mcp_servers.map(m => `<span class="mcp-badge">${m.name}</span>`).join('')}
            </div>
            ${task.depends_on.length ? `<div class="task-deps">Depends on: ${task.depends_on.join(', ')}</div>` : ''}
        </div>
    `).join('');

    if (!valid) {
        document.getElementById('planSummary').innerHTML += `
            <div class="plan-errors">
                <strong>Validation Errors:</strong>
                <ul>${errors.map(e => `<li>${e}</li>`).join('')}</ul>
            </div>
        `;
    }
}

async function approvePlan() {
    showSection('executionMonitor');

    const response = await fetch('/api/execute', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({plan: currentPlan})
    });

    const {execution_id} = await response.json();

    // Connect to SSE for updates
    const eventSource = new EventSource(`/api/stream/${execution_id}`);

    eventSource.onmessage = (event) => {
        const update = JSON.parse(event.data);
        handleExecutionUpdate(update);
    };

    eventSource.onerror = () => {
        eventSource.close();
    };
}

function handleExecutionUpdate(update) {
    const {type, task_id, message, data} = update;

    switch (type) {
        case 'task_started':
            updateTaskCard(task_id, 'running', message);
            break;
        case 'task_completed':
            updateTaskCard(task_id, 'completed', message);
            break;
        case 'task_failed':
            updateTaskCard(task_id, 'failed', message);
            break;
        case 'workflow_done':
            showResults(data.results);
            break;
    }
}
```

---

### Phase 7: Config Updates (`config.py`)

```python
# === WORKFLOW ENGINE ===
MAX_CONCURRENT_SLAVES = 3  # Max parallel task execution
TASK_TIMEOUT = 300  # 5 minutes per task
PLANNER_MODEL = "claude-sonnet-4-20250514"  # Model for planning

# === MCP SERVERS ===
# Environment variables for MCP servers (user provides these)
MCP_ENV_VARS = {
    "GITHUB_TOKEN": os.getenv("GITHUB_TOKEN", ""),
    "SLACK_BOT_TOKEN": os.getenv("SLACK_BOT_TOKEN", ""),
    "BRAVE_API_KEY": os.getenv("BRAVE_API_KEY", ""),
    # Add more as needed
}
```

---

## Execution Order Summary

| Order | File | Dependencies | Effort |
|-------|------|--------------|--------|
| 1 | `models.py` | None | Low |
| 2 | `mcp_registry.py` | models.py | Medium |
| 3 | `planner.py` | models, mcp_registry | High |
| 4 | `slave_agent.py` | models | Medium |
| 5 | `workflow_engine.py` | all above | High |
| 6 | `ui_server.py` | all above | High |
| 7 | `config.py`, `main.py` | all above | Low |

---

## Testing Strategy

1. **Unit test MCP Registry**: Verify suggestion engine, config generation
2. **Test Planner**: Feed sample problems, verify valid JSON output
3. **Test Slave Agent**: Single task execution with mock MCP
4. **Integration test**: End-to-end with simple 2-task workflow
5. **Demo scenario**: Prepare a reliable demo workflow

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Planner produces invalid JSON | Retry with stricter prompt, validate schema |
| MCP server not available | Log warning, continue without that capability |
| Task timeout | Configurable timeout, graceful termination |
| Circular dependencies | Validate in planner, reject invalid plans |
| Rate limiting | Throttle parallel execution |

---

## Demo Scenarios to Prepare

1. **Research task**: "Find the top 3 trending AI papers this week and summarize them"
   - Uses: brave-search, fetch

2. **GitHub automation**: "List open issues in repo X and create a summary report"
   - Uses: github, filesystem

3. **Multi-step pipeline**: "Search for news about [topic], analyze sentiment, save report"
   - Uses: brave-search, fetch, filesystem
